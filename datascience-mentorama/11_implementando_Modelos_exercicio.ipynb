{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_implementando_Modelos_exercicio.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8TIN3lKUZ6vz5fPeK4wFf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eutiagovski/projetos-cursos/blob/main/datascience-mentorama/11_implementando_Modelos_exercicio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OUrhn64Z1Kv5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_friedman1, make_classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Funções dos exercícios\n",
        "\n",
        "def getData():\n",
        "  X, y = make_friedman1(n_samples=10000, n_features=5, noise=0.5, random_state=0)\n",
        "  return X, y\n",
        "\n",
        "def getData2():\n",
        "  X, y = make_classification(n_classes=2, n_features=5, n_samples=10000, random_state=0)\n",
        "  return X, y\n",
        "\n",
        "# Classe regressão linear criada em aula\n",
        "\n",
        "class regLinear():\n",
        "  def __init__(self, learning_rate, num_steps):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_steps = num_steps\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    y = y.reshape(-1, 1)\n",
        "    m = X.shape[0]\n",
        "    k = X.shape[1]\n",
        "    theta = np.random.randn(k + 1, 1)\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "\n",
        "    for step in range(self.num_steps):\n",
        "      gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
        "      theta = theta - self.learning_rate * gradients\n",
        "\n",
        "    self.final_theta = theta\n",
        "    print('Model trained')\n",
        "\n",
        "  def predict(self, X):\n",
        "    m = X.shape[0]\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "    preds = X_b.dot(self.final_theta)\n",
        "    return preds.reshape(-1,)"
      ],
      "metadata": {
        "id": "xsAFj1N912az"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 1: Regressão Linear:"
      ],
      "metadata": {
        "id": "gG-beKFvFtJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parte 1\n",
        "\n",
        "1- Usando a função getData(), carregue os dados disponibilizados.\n",
        "\n",
        "2- Separe parte dos dados para o dataset de teste.\n",
        "\n",
        "3- Usando a metodologia de validação cruzada, teste diferentes parâmetros da regLinear - diferentes learning_rates e num_steps - para escolher a melhor combinação de parâmetros.\n",
        "\n",
        "4- Implemente a regressão linear do scikit-learn e compare os resultados obtidos.\n"
      ],
      "metadata": {
        "id": "yfsaZ9QB5mun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando os dados do exercicio\n",
        "\n",
        "X, y = getData()\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3AuKc0xikpA",
        "outputId": "be1175e9-ba00-4143-a47e-b7a67375693a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 5), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seprando os dados em treino e teste\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "doIaB0YOiteN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain.shape, Xtest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIsj3BRo5_Wr",
        "outputId": "b9a3e4b5-b396-4b42-cf7e-6c375b3f7727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7500, 5), (2500, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## teste de caso:\n",
        "\n",
        "lin_reg = regLinear(num_steps=1, learning_rate=0.25)\n",
        "lin_reg.fit(Xtrain, ytrain)\n",
        "\n",
        "ypred = lin_reg.predict(Xtest)\n",
        "ypred, ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-k_-xGKlZ5u",
        "outputId": "97ca6b02-ed03-4dd8-9105-780ac66bc613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[21.7352223 ],\n",
              "        [23.76019688],\n",
              "        [14.22755497],\n",
              "        ...,\n",
              "        [17.6200454 ],\n",
              "        [12.85730272],\n",
              "        [13.1970261 ]]),\n",
              " array([23.35886272, 22.42612662, 15.12363749, ..., 18.74407227,\n",
              "         3.99198614, 14.87770943]))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "lin_mse = mean_squared_error(ytest, ypred)\n",
        "lin_mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFA5r_u1mi5F",
        "outputId": "777980b3-613b-40c8-d931-bcd2ff8c2fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.86231329318883"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [1, 3, 5, 10, 100, 200]\n",
        "rates = [0.0025, 0.025, 0.5, 0.75, 1, 1.25]\n",
        "\n",
        "for rate in rates:\n",
        " for step in steps:\n",
        "    lin_reg = regLinear(num_steps=step, learning_rate=rate)\n",
        "    lin_reg.fit(Xtrain, ytrain)\n",
        "\n",
        "    ypred = lin_reg.predict(Xtrain)\n",
        "    lin_mse = mean_squared_error(ytrain, ypred)\n",
        "\n",
        "    print(f'Step: {step}')\n",
        "    print(f'Learning Rate: {rate}')\n",
        "    print(f'Rmse: {np.sqrt(np.mean(np.square(ytrain - ypred)))}')\n",
        "    print()        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv8epVSktvRV",
        "outputId": "e2241b2d-3bdd-40d6-daa4-f9de893b1e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.0025\n",
            "Rmse: 17.267002513132766\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.0025\n",
            "Rmse: 14.700402747769225\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.0025\n",
            "Rmse: 12.896831453597956\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.0025\n",
            "Rmse: 12.776868710511684\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.0025\n",
            "Rmse: 6.797140035879628\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.0025\n",
            "Rmse: 5.49992245261138\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.025\n",
            "Rmse: 13.901535634897423\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.025\n",
            "Rmse: 12.091275418341242\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.025\n",
            "Rmse: 8.211172147975931\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.025\n",
            "Rmse: 5.968832965826814\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.025\n",
            "Rmse: 5.497174186769912\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.025\n",
            "Rmse: 5.812730564386747\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.5\n",
            "Rmse: 19.176848468223646\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.5\n",
            "Rmse: 29.781058340835646\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.5\n",
            "Rmse: 59.16965577788365\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.5\n",
            "Rmse: 191.17471777740695\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.5\n",
            "Rmse: 1151804945477.548\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.5\n",
            "Rmse: 9.141196094889318e+22\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.75\n",
            "Rmse: 35.477694745146415\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.75\n",
            "Rmse: 242.62518064781435\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.75\n",
            "Rmse: 1259.6869280079911\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.75\n",
            "Rmse: 111379.88784868608\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.75\n",
            "Rmse: 5.285017560602704e+39\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.75\n",
            "Rmse: 1.7698543806838514e+78\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 1\n",
            "Rmse: 57.99679038744269\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 1\n",
            "Rmse: 721.2547739015511\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 1\n",
            "Rmse: 9151.887891874367\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 1\n",
            "Rmse: 5370099.87721269\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 1\n",
            "Rmse: 2.393556419275213e+56\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 1\n",
            "Rmse: 6.065204050391376e+111\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 1.25\n",
            "Rmse: 69.21778299250101\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 1.25\n",
            "Rmse: 1350.7708517792432\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 1.25\n",
            "Rmse: 33475.10755344439\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 1.25\n",
            "Rmse: 63962688.83856646\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 1.25\n",
            "Rmse: 3.377434715796261e+68\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 1.25\n",
            "Rmse: 7.73084730523841e+135\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Melhores parâmetros para o modelo\n",
        "\n",
        "lin_reg = regLinear(num_steps=200, learning_rate=0.75)\n",
        "\n",
        "lin_reg.fit(Xtrain, ytrain)\n",
        "ypred = lin_reg.predict(Xtrain)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytrain, ypred)}')\n",
        "print(f'RMSE: {np.sqrt(np.mean(np.square(ytrain - ypred)))}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-xWcmFdwv0i",
        "outputId": "e7c90f84-a582-4034-9591-9db387932a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "MSE: 3.660129814671154e+156\n",
            "RMSE: 1.913146574277867e+78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparando com o modelo do sklearn\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "lin_reg.fit(Xtrain, ytrain)\n",
        "\n",
        "ypred = lin_reg.predict(Xtrain)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytrain, ypred)}')\n",
        "print(f'RMSE: {np.sqrt(np.mean(np.square(ytrain - ypred)))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7iMGXxAumZZ",
        "outputId": "63ec6f0e-f58c-434c-bafd-c403eda265ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 6.049563628914155\n",
            "RMSE: 2.459586068612797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validando no conjunto de testes:\n",
        "\n",
        "lin_reg = regLinear(num_steps=200, learning_rate=0.75)\n",
        "\n",
        "lin_reg.fit(Xtest, ytest)\n",
        "ypred = lin_reg.predict(Xtest)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytest, ypred)}')\n",
        "print(f'RMSE: {np.sqrt(np.mean(np.square(ytest - ypred)))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKD6SWu84EqZ",
        "outputId": "cda1a826-25bd-4ca5-995c-e2d4199e4c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "MSE: 1.123770385255462e+157\n",
            "RMSE: 3.352268463675696e+78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parte 2\n",
        "Introdução__\n",
        "\n",
        "Para cada variável explicativa $X_1, .., X_5$, crie outras variáveis usando o __quadrado__ de cada um delas. Desta forma, o conjunto final será de 10 variáveis, em que:\n",
        "\n",
        "$X_6 = (X_1)^{2}$, $X_7 = (X_2)^{2}$, $X_8 = (X_3)^{2}$, $X_9 = (X_4)^{2}$, $X_{10} = (X_5)^{2}$.\n",
        "\n",
        "Ao treinarmos uma regressão linear com essas 10 variáveis, a predição é da forma:\n",
        "\n",
        "$y_{pred} = \\theta_0 + \\theta_1 \\cdot X_1 + .. + \\theta_5 \\cdot X_5 + \\theta_6 \\cdot (X_1)^{2} + .. + \\theta_{10} \\cdot (X_5)^{2}$\n",
        "\n",
        "Como estamos usando o quadrado das variáveis explicativas, dizemos que temos um __modelo de regressão polinomial de grau 2__. Podemos ter variações deste modelo:\n",
        "\n",
        "-Podemos aumentar o grau: basta mudar a potência que elevamos as variáveis. Por exemplo, podemos incluir o __cubo__ das variáveis e termos um modelo polinomial de ordem 3.\n",
        "\n",
        "-Podemos ter __interações__ entre as variáveis: multiplicações entre as variáveis.\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "$y_{pred} = \\theta_0 + \\theta_1 \\cdot X_1 + .. + \\theta_5 \\cdot X_5 + \\theta_6 \\cdot (X_1)^{2} + .. + \\theta_{10} \\cdot (X_5)^{2} + \\theta_{11} \\cdot (X_1)^{3} + \\theta_{12} \\cdot V1 + \\theta_{13} \\cdot V2$,\n",
        "\n",
        "onde\n",
        "\n",
        "$V_1 = X_1 \\cdot X_2$ e $V_2 = (X_2)^{2} \\cdot X_4$\n",
        "\n",
        "Exercício__\n",
        "\n",
        "1- Estude o link:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
        "\n",
        "em que é discutido como criar modelos polinomiais com o scikit-learn de forma detalhada.\n",
        "\n",
        "2- Repita os passos da primeira parte, mas agora considerando polinômios de graus 2 ou mais.\n",
        "\n",
        "3- Inclua regularização Ridge e Lasso nas análises e teste os resultados para diferentes parâmetros $\\alpha$.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "DrxzILCd0g9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# realizando o quadrado das variáveis X\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly_features.fit_transform(Xtrain)\n",
        "X_poly.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtapvzH1yls5",
        "outputId": "555590c2-62bb-400a-ecc4-eaa7e2d263b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7500, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_poly[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdveHFET3AoE",
        "outputId": "19223889-678b-4938-fa8a-301c4446dfd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.54137349e-01, 4.39491629e-01, 7.42546626e-01, 5.84881233e-02,\n",
              "        2.31813099e-02, 4.27895671e-01, 2.87487889e-01, 4.85727481e-01,\n",
              "        3.82592659e-02, 1.51637606e-02, 1.93152892e-01, 3.26343027e-01,\n",
              "        2.57050406e-02, 1.01879916e-02, 5.51375492e-01, 4.34301587e-02,\n",
              "        1.72132034e-02, 3.42086057e-03, 1.35583131e-03, 5.37373126e-04],\n",
              "       [8.45075242e-01, 1.67746108e-01, 1.03945363e-01, 6.11141276e-01,\n",
              "        4.95987227e-02, 7.14152164e-01, 1.41758083e-01, 8.78416527e-02,\n",
              "        5.16460362e-01, 4.19146526e-02, 2.81387567e-02, 1.74364301e-02,\n",
              "        1.02516570e-01, 8.31999269e-03, 1.08046385e-02, 6.35253017e-02,\n",
              "        5.15555723e-03, 3.73493659e-01, 3.03118267e-02, 2.46003329e-03],\n",
              "       [4.46516825e-01, 9.86511266e-01, 1.50774754e-01, 4.42882415e-01,\n",
              "        3.74080187e-01, 1.99377275e-01, 4.40493879e-01, 6.73234643e-02,\n",
              "        1.97754450e-01, 1.67033098e-01, 9.73204477e-01, 1.48740993e-01,\n",
              "        4.36908492e-01, 3.69034319e-01, 2.27330263e-02, 6.67754870e-02,\n",
              "        5.64018480e-02, 1.96144834e-01, 1.65673537e-01, 1.39935986e-01],\n",
              "       [4.04527879e-01, 1.70251963e-01, 1.20927118e-01, 9.01356164e-01,\n",
              "        8.10244084e-01, 1.63642804e-01, 6.88716654e-02, 4.89183905e-02,\n",
              "        3.64623697e-01, 3.27766321e-01, 2.89857309e-02, 2.05880792e-02,\n",
              "        1.53457656e-01, 1.37945646e-01, 1.46233679e-02, 1.08998403e-01,\n",
              "        9.79804820e-02, 8.12442934e-01, 7.30318500e-01, 6.56495476e-01],\n",
              "       [8.07958589e-02, 2.04666446e-01, 8.09685654e-01, 7.22705585e-02,\n",
              "        3.03247302e-01, 6.52797082e-03, 1.65362013e-02, 6.54192479e-02,\n",
              "        5.83916185e-03, 2.45011262e-02, 4.18883541e-02, 1.65715485e-01,\n",
              "        1.47913584e-02, 6.20645476e-02, 6.55590859e-01, 5.85164345e-02,\n",
              "        2.45534990e-01, 5.22303363e-03, 2.19158519e-02, 9.19589262e-02],\n",
              "       [3.26679426e-01, 1.76811756e-01, 5.49965914e-01, 4.35019366e-01,\n",
              "        7.81985756e-01, 1.06719447e-01, 5.77607629e-02, 1.79662549e-01,\n",
              "        1.42111877e-01, 2.55458658e-01, 3.12623970e-02, 9.72404390e-02,\n",
              "        7.69165380e-02, 1.38264275e-01, 3.02462507e-01, 2.39245823e-01,\n",
              "        4.30065511e-01, 1.89241849e-01, 3.40178948e-01, 6.11501722e-01],\n",
              "       [9.57778772e-01, 4.28724211e-01, 4.92740850e-01, 3.07792537e-01,\n",
              "        2.80031925e-01, 9.17340176e-01, 4.10622948e-01, 4.71936726e-01,\n",
              "        2.94797158e-01, 2.68208633e-01, 1.83804449e-01, 2.11249932e-01,\n",
              "        1.31958113e-01, 1.20056466e-01, 2.42793545e-01, 1.51661956e-01,\n",
              "        1.37983169e-01, 9.47362458e-02, 8.61917366e-02, 7.84178789e-02],\n",
              "       [7.68919436e-01, 8.56567468e-01, 7.20319266e-01, 9.79010919e-01,\n",
              "        8.98825219e-01, 5.91237099e-01, 6.58631374e-01, 5.53867484e-01,\n",
              "        7.52780524e-01, 6.91124181e-01, 7.33707827e-01, 6.17002050e-01,\n",
              "        8.38588904e-01, 7.69904442e-01, 5.18859845e-01, 7.05200427e-01,\n",
              "        6.47441122e-01, 9.58462380e-01, 8.79959704e-01, 8.07886775e-01],\n",
              "       [6.09970356e-02, 9.91423311e-01, 5.70376718e-01, 4.59004023e-01,\n",
              "        1.97894308e-02, 3.72063836e-03, 6.04738830e-02, 3.47912890e-02,\n",
              "        2.79978847e-02, 1.20709662e-03, 9.82920181e-01, 5.65484774e-01,\n",
              "        4.55067288e-01, 1.96197030e-02, 3.25329600e-01, 2.61805208e-01,\n",
              "        1.12874306e-02, 2.10684693e-01, 9.08342836e-03, 3.91621573e-04],\n",
              "       [9.31776451e-01, 9.99948970e-01, 2.69888821e-01, 3.01768552e-01,\n",
              "        1.64988939e-01, 8.68207355e-01, 9.31728903e-01, 2.51476047e-01,\n",
              "        2.81180831e-01, 1.53732808e-01, 9.99897943e-01, 2.69875048e-01,\n",
              "        3.01753153e-01, 1.64980520e-01, 7.28399755e-02, 8.14439586e-02,\n",
              "        4.45286702e-02, 9.10642591e-02, 4.97884733e-02, 2.72213501e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testando no modelo de rgressão do sklearn\n",
        "\n",
        "poly_fit = LinearRegression()\n",
        "poly_fit.fit(X_poly, ytrain)\n",
        "\n",
        "y_new = poly_fit.predict(X_poly)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytrain, y_new)}')\n",
        "print(f'RMSE: {np.sqrt(np.mean(np.square(ytrain - y_new)))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjBBY_MP3RH5",
        "outputId": "283c7862-0231-4eac-dfac-33e523c3186e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.981269729714431\n",
            "RMSE: 1.4075758344453173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testando no modelo consolidado de regressão linear\n",
        "\n",
        "poly_fit = regLinear(num_steps=200, learning_rate=0.75)\n",
        "poly_fit.fit(X_poly, ytrain)\n",
        "\n",
        "y_new = poly_fit.predict(X_poly)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytrain, y_new)}')\n",
        "print(f'RMSE: {np.sqrt(np.mean(np.square(ytrain - y_new)))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07UrLpc83cDZ",
        "outputId": "fe32fdd3-3484-44f0-81f3-fa931d42c8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "MSE: 1.2643995787615632e+261\n",
            "RMSE: 3.555839674059513e+130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## procurando o melhor parâmetro\n",
        "\n",
        "steps = [1, 3, 5, 10, 100, 200]\n",
        "rates = [0.0025, 0.025, 0.5, 0.75, 1, 1.25]\n",
        "\n",
        "for rate in rates:\n",
        "  for step in steps:\n",
        "      lin_reg = regLinear(num_steps=step, learning_rate=rate)\n",
        "      lin_reg.fit(X_poly, ytrain)\n",
        "\n",
        "      ypred = lin_reg.predict(X_poly)\n",
        "      lin_mse = mean_squared_error(ytrain, ypred)\n",
        "\n",
        "      print(f'Step: {step}')\n",
        "      print(f'Learning Rate: {rate}')\n",
        "      print(f'Mse: {mean_squared_error(ytrain, ypred)}')\n",
        "      print(f'Rmse: {np.sqrt(np.mean(np.square(ytrain - ypred)))}')\n",
        "      print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vj_hQbF4IhC",
        "outputId": "7510e332-9405-4d88-ee93-674a26f80fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.0025\n",
            "Mse: 136.35282913205108\n",
            "Rmse: 12.078276880261233\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.0025\n",
            "Mse: 213.59190962484732\n",
            "Rmse: 14.582112829809118\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.0025\n",
            "Mse: 243.49642300276741\n",
            "Rmse: 15.636452359827157\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.0025\n",
            "Mse: 111.7502626194361\n",
            "Rmse: 10.796282283593575\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.0025\n",
            "Mse: 15.466497902566148\n",
            "Rmse: 6.267989177161196\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.0025\n",
            "Mse: 10.060774860939256\n",
            "Rmse: 6.112374822660034\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.025\n",
            "Mse: 196.70927057192327\n",
            "Rmse: 14.139060569644794\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.025\n",
            "Mse: 69.56476913360258\n",
            "Rmse: 9.177761822089979\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.025\n",
            "Mse: 33.07099024860825\n",
            "Rmse: 7.115695187077639\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.025\n",
            "Mse: 14.14720238921846\n",
            "Rmse: 6.2679674777810686\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.025\n",
            "Mse: 7.6711260002755965\n",
            "Rmse: 6.173627814774613\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.025\n",
            "Mse: 6.62559849574366\n",
            "Rmse: 6.3126736250306275\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.5\n",
            "Mse: 1189.844124087657\n",
            "Rmse: 35.765142320926266\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.5\n",
            "Mse: 63447.80932781254\n",
            "Rmse: 252.85242212020904\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.5\n",
            "Mse: 3465115.836087564\n",
            "Rmse: 1862.400182489956\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.5\n",
            "Mse: 32728638283.975014\n",
            "Rmse: 180909.67063066416\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.5\n",
            "Mse: 1.1223354228154708e+86\n",
            "Rmse: 1.0594033333983176e+43\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.5\n",
            "Mse: 4.0443386491509764e+169\n",
            "Rmse: 6.3595114978675725e+84\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.75\n",
            "Mse: 4821.48342717818\n",
            "Rmse: 70.54443366049027\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.75\n",
            "Mse: 1925883.7050200133\n",
            "Rmse: 1388.6836341700016\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.75\n",
            "Mse: 648320160.796926\n",
            "Rmse: 25463.042865925338\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.75\n",
            "Mse: 1502783452266026.2\n",
            "Rmse: 38765750.111196965\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.75\n",
            "Mse: 6.2471112120008006e+131\n",
            "Rmse: 7.90386690930508e+65\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.75\n",
            "Mse: 7.454426969907831e+260\n",
            "Rmse: 2.730279650495135e+130\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 1\n",
            "Mse: 7625.2920802226745\n",
            "Rmse: 88.4062227175653\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 1\n",
            "Mse: 14817625.005880518\n",
            "Rmse: 3850.28140198894\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 1\n",
            "Mse: 17894728531.43706\n",
            "Rmse: 133772.09024611532\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 1\n",
            "Mse: 1.6084873603773256e+18\n",
            "Rmse: 1268261549.5504637\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 1\n",
            "Mse: 3.0432426031952627e+161\n",
            "Rmse: 5.516559256633851e+80\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 1\n",
            "Mse: inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n",
            "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n",
            "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in square\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rmse: inf\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 1.25\n",
            "Mse: 17336.499128893694\n",
            "Rmse: 132.68242621209671\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 1.25\n",
            "Mse: 76694930.70490895\n",
            "Rmse: 8758.476458962674\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 1.25\n",
            "Mse: 152801706868.71603\n",
            "Rmse: 390899.49939528387\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 1.25\n",
            "Mse: 3.469829720859526e+20\n",
            "Rmse: 18627478950.51925\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 1.25\n",
            "Mse: 2.425117191909739e+183\n",
            "Rmse: 4.924547889816625e+91\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 1.25\n",
            "Mse: inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n",
            "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n",
            "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rmse: inf\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in square\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consolidando os melhores parâmetros: \n",
        "\n",
        "lin_reg_poly_best = regLinear(learning_rate=0.5, num_steps=100)\n",
        "lin_reg_poly_best.fit(X_poly, ytrain)\n",
        "\n",
        "y_new = lin_reg_poly_best.predict(X_poly)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytrain, y_new)}')\n",
        "print(f'RMSE: {np.sqrt(np.mean(np.square(ytrain - y_new)))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_7xauQT5p49",
        "outputId": "9f0b77d9-97af-4317-8483-932ff0c07d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "MSE: 1.1997127881378082e+86\n",
            "RMSE: 1.0953140134855431e+43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validando no conjunto de testes:\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly_test = poly_features.fit_transform(Xtest)\n",
        "\n",
        "lin_reg_poly_best = regLinear(learning_rate=0.5, num_steps=100)\n",
        "lin_reg_poly_best.fit(X_poly_test, ytest)\n",
        "\n",
        "y_new = lin_reg_poly_best.predict(X_poly_test)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytest, y_new)}')\n",
        "print(f'RMSE: {np.sqrt(np.mean(np.square(ytest - y_new)))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKhOjW1Q6DQq",
        "outputId": "b5bf789a-d8e7-44dd-d9ca-fc8daf6c27d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "MSE: 1.5988566509071223e+87\n",
            "RMSE: 3.998570558220926e+43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def polyFit(X, y, grau):\n",
        "  poylbig_features = PolynomialFeatures(degree=grau, include_bias=False)\n",
        "  std_scaler = StandardScaler()\n",
        "  lin_reg = LinearRegression()\n",
        "\n",
        "  polynomial_regressor = Pipeline([\n",
        "                                   ('poly_features', poylbig_features),\n",
        "                                   ('std_scaler', std_scaler),\n",
        "                                   ('lin_reg', lin_reg),\n",
        "  ])\n",
        "\n",
        "  polynomial_regressor.fit(X, y)\n",
        "  return polynomial_regressor"
      ],
      "metadata": {
        "id": "Has1rpS28WBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for grau in [1,2,5,10]:\n",
        "  print()\n",
        "\n",
        "  polyfit = polyFit(Xtrain, ytrain, grau)\n",
        "\n",
        "  ypoly = polyfit.predict(Xtrain)\n",
        "\n",
        "  print(f'Grau: {grau}')\n",
        "  print(f'RMSE: {np.sqrt(np.mean(np.square(ytrain - ypoly)))}')\n",
        "  print('-' * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc4vRgPA8bk7",
        "outputId": "92956e6d-f33d-41d6-cc2b-fb8ff89c6946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Grau: 1\n",
            "RMSE: 2.4595860686127966\n",
            "------------------------------------------------------------\n",
            "\n",
            "Grau: 2\n",
            "RMSE: 1.4075758344453173\n",
            "------------------------------------------------------------\n",
            "\n",
            "Grau: 5\n",
            "RMSE: 0.4931481456953378\n",
            "------------------------------------------------------------\n",
            "\n",
            "Grau: 10\n",
            "RMSE: 0.38775558354102774\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "def polyFitReg(X, y, grau, base_model, base_model_name):\n",
        "  poylbig_features = PolynomialFeatures(degree=grau, include_bias=False)\n",
        "  std_scaler = StandardScaler()\n",
        "  basemodel = base_model\n",
        "\n",
        "  polynomial_regressor = Pipeline([\n",
        "                                   ('poly_features', poylbig_features),\n",
        "                                   ('std_scaler', std_scaler),\n",
        "                                   (base_model_name, basemodel),\n",
        "  ])\n",
        "\n",
        "  polynomial_regressor.fit(X, y)\n",
        "  return polynomial_regressor\n",
        "\n",
        "grau = 10\n",
        "\n",
        "for alpha in [0, 0.001, 0.01, 1, 10, 100, 10000]:\n",
        "  model_name = 'Ridge_alpha: ' + str(alpha)\n",
        "  polyfit = polyFitReg(Xtrain,\n",
        "                       ytrain, \n",
        "                       grau, \n",
        "                       base_model = Ridge(alpha=alpha),\n",
        "                       base_model_name = model_name)\n",
        "  \n",
        "  ypoly_novo = polyfit.predict(Xtest)\n",
        "\n",
        "  print(model_name)\n",
        "\n",
        "  train_error = np.sqrt(np.mean(np.square(ytrain - polyfit.predict(Xtrain))))\n",
        "  test_error = np.sqrt(np.mean(np.square(ytest - polyfit.predict(Xtest))))\n",
        "\n",
        "  print(f'RMSE (treino): {train_error}')\n",
        "  print(f'RMSE (teste): {test_error}')\n",
        "\n",
        "  print(f'{train_error-test_error*-1}')\n",
        "\n",
        "  print('-' * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7LQ_VpO87T-",
        "outputId": "f97593ee-0ede-4716-9851-53458a87c1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:156: LinAlgWarning: Ill-conditioned matrix (rcond=1.627e-18): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge_alpha: 0\n",
            "RMSE (treino): 0.3877723443117173\n",
            "RMSE (teste): 1.1295117927592704\n",
            "1.5172841370709877\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 0.001\n",
            "RMSE (treino): 0.45158128325835956\n",
            "RMSE (teste): 0.5608284863667962\n",
            "1.0124097696251557\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 0.01\n",
            "RMSE (treino): 0.4634325230674249\n",
            "RMSE (teste): 0.537798688828515\n",
            "1.0012312118959399\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 1\n",
            "RMSE (treino): 0.48206007653380534\n",
            "RMSE (teste): 0.5159412952316388\n",
            "0.9980013717654441\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 10\n",
            "RMSE (treino): 0.5025495738487654\n",
            "RMSE (teste): 0.5268198234202932\n",
            "1.0293693972690585\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 100\n",
            "RMSE (treino): 0.6044552098858843\n",
            "RMSE (teste): 0.6231022567574963\n",
            "1.2275574666433806\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 10000\n",
            "RMSE (treino): 1.7191601718670273\n",
            "RMSE (teste): 1.7992973049276424\n",
            "3.5184574767946697\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 2: Regressão Logística:\n"
      ],
      "metadata": {
        "id": "xHT5Zg73GMhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parte 1\n",
        "\n",
        "Crie uma classe regLogistica para treinar o modelo de regressão logística. Essa classe deve ser usada para problemas de classificação binária, cuja variável target assume os valores: 0 (classe negativa) e 1 (classe positiva).\n",
        "\n",
        "O método construtor dessa classe deve possuir 3 parâmetros: learning_rate, num_steps e limiar.\n",
        "\n",
        "Os outros médotos devem ser:\n",
        "\n",
        "    - médoto fit: para treinar o modelo - usando gradient descent\n",
        "    \n",
        "    - médoto predict_proba: para retornar a probabilidade da classe 1\n",
        "    \n",
        "    - médoto predict: retornar a classe predita: 0 ou 1 - dependente do limiar\n",
        "    \n"
      ],
      "metadata": {
        "id": "z4PnCSFv6AIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class regLogistica:\n",
        "  def __init__(self, learning_rate=0.01, num_steps=10, limiar=0.8, info=False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_steps = num_steps\n",
        "    self.limiar = limiar\n",
        "    self.info = info\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    y = y.reshape(-1, 1)\n",
        "    # treinar o modelo segundo o método gradient descent\n",
        "    \n",
        "    # primeiro reshape os dados para o formato adequado\n",
        "    X_b = np.c_[np.ones(X.shape[0]), X]\n",
        "    theta = np.random.randn(X_b.shape[1], 1)\n",
        "\n",
        "    for step in range(self.num_steps):\n",
        "      #Calculando a probabilidade\n",
        "      yscores = (1 / (1 + np.exp(-X_b.dot(theta))))\n",
        "\n",
        "      #Calculando o gradiente do logloss\n",
        "      gradient = X_b.T.dot(yscores -y)\n",
        "\n",
        "      #Atualizando os pesos\n",
        "      theta = theta - self.learning_rate * gradient\n",
        "\n",
        "      #Calculando o logloss nos passos\n",
        "      self.logloss_step = ((y * np.log(yscores) + (1 - y) * np.log(1 - yscores)).mean() * -1)\n",
        "\n",
        "      #Printa as informações\n",
        "      if self.info:\n",
        "        print(f'Step: {step}')\n",
        "        print(f'Theta: {theta.reshape(-1,)}')\n",
        "        print(f'LogLoss: {self.logloss_step}')\n",
        "        print()\n",
        "        print('Model Trained!')\n",
        "        print('-' * 60)\n",
        "        print()\n",
        "\n",
        "      self.theta_final = theta\n",
        "\n",
        "  def predict(self, X):\n",
        "    self.ypred = np.where(X > self.limiar, 1, 0)\n",
        "    return self.ypred\n",
        "  \n",
        "  def predict_proba(self, X):\n",
        "    m = X.shape[0]\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "    probs = (X_b.dot(self.theta_final))\n",
        "    return probs\n"
      ],
      "metadata": {
        "id": "H0ZGc_JN4uZL"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parte 2\n",
        "\n",
        "Usando a função getData2(), carregue o dataset disponibilizado.\n",
        "\n",
        "Use a regLogistica, classe criada na parte 1 do exercício, para treinar modelos nestes dados. Use validação cruzada para seleção dos parâmetros. Considere diferentes métricas de classificação e justifique as escolhas.\n"
      ],
      "metadata": {
        "id": "AZ2VcGYRGQxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = getData2()\n",
        "X, y"
      ],
      "metadata": {
        "id": "IorX92dt1B6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d47f7a1-fd39-44d2-a91a-9b86ca353772"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.82380715, -0.59163837,  0.13041933, -0.40345475,  1.16360785],\n",
              "        [ 0.7091986 ,  0.60606127, -0.37678226,  0.39654936, -1.15961369],\n",
              "        [ 1.61194498,  0.36486859,  1.91264129,  0.38601731, -0.31972146],\n",
              "        ...,\n",
              "        [ 1.38015938,  1.43125078, -1.42179351,  0.89985272, -0.70967569],\n",
              "        [-1.63030207, -0.23544436, -2.29968645, -0.32243952, -1.49535664],\n",
              "        [ 1.07627839,  1.178116  , -1.27826779,  0.73327205, -1.27906183]]),\n",
              " array([0, 1, 1, ..., 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_log = regLogistica(learning_rate=0.0001, num_steps=10, limiar=0.9, info=True)\n",
        "reg_log.fit(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-SBtCFBG7M_",
        "outputId": "847ca5c8-779d-4f22-b403-1cb34629547a"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0\n",
            "Theta: [ 1.6368773   0.55419767  0.65963913  0.53650266 -1.96427246  2.30179449]\n",
            "LogLoss: 1.4392522469901945\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 1\n",
            "Theta: [ 1.43346586  0.53159113  0.52498652  0.86388505 -2.03560216  2.03639424]\n",
            "LogLoss: 1.086414380811293\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 2\n",
            "Theta: [ 1.25557412  0.52542086  0.4403946   1.08405542 -2.07941488  1.79777894]\n",
            "LogLoss: 0.8714401593430686\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 3\n",
            "Theta: [ 1.10107583  0.52890078  0.38906493  1.23069582 -2.10510221  1.58785682]\n",
            "LogLoss: 0.7406615580116819\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 4\n",
            "Theta: [ 0.96589911  0.53678385  0.35845947  1.32861716 -2.11969646  1.40353153]\n",
            "LogLoss: 0.6563525785354732\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 5\n",
            "Theta: [ 0.8466067   0.54607846  0.34077874  1.39374522 -2.12753833  1.24093623]\n",
            "LogLoss: 0.5982404457564496\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 6\n",
            "Theta: [ 0.74066178  0.55523212  0.33129554  1.43620319 -2.13122628  1.09677987]\n",
            "LogLoss: 0.5559973608795439\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 7\n",
            "Theta: [ 0.64620522  0.56346175  0.3270635   1.4626339  -2.13235696  0.96847795]\n",
            "LogLoss: 0.5241267502772415\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 8\n",
            "Theta: [ 0.56182609  0.57039239  0.32617245  1.47758362 -2.13194897  0.8540029 ]\n",
            "LogLoss: 0.4994832006404109\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 9\n",
            "Theta: [ 0.48640502  0.57587674  0.32734433  1.48428114 -2.13067099  0.75173179]\n",
            "LogLoss: 0.48012708442582835\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = reg_log.predict_proba(X)\n"
      ],
      "metadata": {
        "id": "CyHKqh9GI3SO"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = reg_log.predict(probs)"
      ],
      "metadata": {
        "id": "h5JPTyvDHNoA"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcvJgcToJriE",
        "outputId": "01265e91-7f8c-4dd3-c030-963596b95315"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 1), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def auc_score(y, ypred):\n",
        "  accuracy = roc_auc_score(y, ypred)\n",
        "  print(f'Precisão: {(accuracy *100).round(2)}%')\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "K0EBF7egS8c_"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score(y, ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPeogL4cTK-2",
        "outputId": "4eae3872-9416-426e-af66-53c2def541ce"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão: 80.24%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8024330755036286"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "CNi5RebPPubx"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_best(X_train, y_train, steps, rates):\n",
        "  for rate in rates:\n",
        "    for step in steps:\n",
        "        reg_log = regLogistica(learning_rate=rate, num_steps=step, limiar=0.8)\n",
        "        reg_log.fit(X_train, y_train)\n",
        "\n",
        "        ypred = reg_log.predict(reg_log.predict_proba(X_train))\n",
        "        score = reg_log.logloss_step\n",
        "\n",
        "        print(f'Steps: {step}')\n",
        "        print(f'Learning Rate: {rate}')\n",
        "        print(f'LogLoss: {score}')\n",
        "        print()  "
      ],
      "metadata": {
        "id": "rlzYAsJ8MSGh"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [2, 8, 16, 20]\n",
        "rates = [0.0001, 0.0005, 0.001, 0.005]\n",
        "\n",
        "search_best(X_train, y_train, steps=steps, rates=rates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGw10TXVOwne",
        "outputId": "e1f935aa-232c-4e66-c05c-c334ad25f814"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 2\n",
            "Learning Rate: 0.0001\n",
            "LogLoss: 2.075086670841956\n",
            "\n",
            "Steps: 8\n",
            "Learning Rate: 0.0001\n",
            "LogLoss: 0.46352867279704374\n",
            "\n",
            "Steps: 16\n",
            "Learning Rate: 0.0001\n",
            "LogLoss: 0.4087133914178898\n",
            "\n",
            "Steps: 20\n",
            "Learning Rate: 0.0001\n",
            "LogLoss: 0.40324484806727995\n",
            "\n",
            "Steps: 2\n",
            "Learning Rate: 0.0005\n",
            "LogLoss: 0.46608173628076827\n",
            "\n",
            "Steps: 8\n",
            "Learning Rate: 0.0005\n",
            "LogLoss: 0.4025219485870364\n",
            "\n",
            "Steps: 16\n",
            "Learning Rate: 0.0005\n",
            "LogLoss: 0.40251871192896804\n",
            "\n",
            "Steps: 20\n",
            "Learning Rate: 0.0005\n",
            "LogLoss: 0.402518617859431\n",
            "\n",
            "Steps: 2\n",
            "Learning Rate: 0.001\n",
            "LogLoss: 0.6361259037496491\n",
            "\n",
            "Steps: 8\n",
            "Learning Rate: 0.001\n",
            "LogLoss: 0.4025294542887039\n",
            "\n",
            "Steps: 16\n",
            "Learning Rate: 0.001\n",
            "LogLoss: 0.40251862101588926\n",
            "\n",
            "Steps: 20\n",
            "Learning Rate: 0.001\n",
            "LogLoss: 0.40251863035387037\n",
            "\n",
            "Steps: 2\n",
            "Learning Rate: 0.005\n",
            "LogLoss: nan\n",
            "\n",
            "Steps: 8\n",
            "Learning Rate: 0.005\n",
            "LogLoss: nan\n",
            "\n",
            "Steps: 16\n",
            "Learning Rate: 0.005\n",
            "LogLoss: nan\n",
            "\n",
            "Steps: 20\n",
            "Learning Rate: 0.005\n",
            "LogLoss: nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in multiply\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_log = regLogistica(learning_rate=0.0005, num_steps=20, limiar=0.9, info=True)\n",
        "reg_log.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmGdtMtLQba2",
        "outputId": "b4513dd7-70c0-4e89-e3c8-56443b12218b"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0\n",
            "Theta: [ 0.10348466 -0.37595466 -1.13612361  2.17649411  0.28787232  0.44417244]\n",
            "LogLoss: 2.0982811623026487\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 1\n",
            "Theta: [-0.0198917  -0.12127501 -0.90496857  2.00423798  0.43715305  0.28461909]\n",
            "LogLoss: 0.475258960666341\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 2\n",
            "Theta: [-0.08285961 -0.01043048 -0.77283717  1.84306239  0.51816689  0.16010748]\n",
            "LogLoss: 0.42947712293708\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 3\n",
            "Theta: [-0.10276518  0.01148275 -0.71376956  1.7211102   0.5509479   0.07305722]\n",
            "LogLoss: 0.4123800530338971\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 4\n",
            "Theta: [-1.03604113e-01  1.17184769e-03 -6.89863872e-01  1.63712553e+00\n",
            "  5.61831110e-01  1.88002299e-02]\n",
            "LogLoss: 0.40641306547927214\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 5\n",
            "Theta: [-0.09917987 -0.01275008 -0.67874164  1.58157666  0.56576046 -0.01234522]\n",
            "LogLoss: 0.4040567645947967\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 6\n",
            "Theta: [-0.09432321 -0.02297845 -0.67249904  1.54603949  0.56766581 -0.02926815]\n",
            "LogLoss: 0.40310069161367346\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 7\n",
            "Theta: [-0.09030059 -0.02944385 -0.66869343  1.5239601   0.56879877 -0.0381117 ]\n",
            "LogLoss: 0.4027311906640514\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 8\n",
            "Theta: [-0.08729516 -0.03331835 -0.66633936  1.51052769  0.56951511 -0.04259925]\n",
            "LogLoss: 0.40259467228651535\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 9\n",
            "Theta: [-0.08517394 -0.03559001 -0.66488952  1.50246175  0.56997054 -0.04482284]\n",
            "LogLoss: 0.4025455808370552\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 10\n",
            "Theta: [-0.08373161 -0.03690947 -0.66400218  1.49765311  0.57025808 -0.04590111]\n",
            "LogLoss: 0.40252815534892844\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 11\n",
            "Theta: [-0.08277628 -0.0376732  -0.66346172  1.49479634  0.57043818 -0.0464123 ]\n",
            "LogLoss: 0.4025219960135626\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 12\n",
            "Theta: [-0.08215549 -0.0381151  -0.6631336   1.49310128  0.57055022 -0.04664814]\n",
            "LogLoss: 0.4025198177900739\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 13\n",
            "Theta: [-0.08175783 -0.03837112 -0.66293483  1.49209553  0.57061955 -0.04675299]\n",
            "LogLoss: 0.4025190454192985\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 14\n",
            "Theta: [-0.08150588 -0.03851976 -0.66281459  1.49149837  0.57066226 -0.04679704]\n",
            "LogLoss: 0.40251877062551406\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 15\n",
            "Theta: [-0.08134762 -0.03860629 -0.66274193  1.49114347  0.57068848 -0.0468138 ]\n",
            "LogLoss: 0.4025186725352258\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 16\n",
            "Theta: [-0.08124889 -0.0386568  -0.66269806  1.4909323   0.57070453 -0.0468189 ]\n",
            "LogLoss: 0.4025186374179078\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 17\n",
            "Theta: [-0.08118764 -0.03868636 -0.66267158  1.49080651  0.57071433 -0.04681943]\n",
            "LogLoss: 0.40251862481455924\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 18\n",
            "Theta: [-0.08114981 -0.03870371 -0.6626556   1.49073151  0.5707203  -0.04681845]\n",
            "LogLoss: 0.4025186202822915\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 19\n",
            "Theta: [-0.08112653 -0.03871391 -0.66264596  1.49068673  0.57072394 -0.0468172 ]\n",
            "LogLoss: 0.4025186186498817\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = reg_log.predict_proba(X_train)\n",
        "ypred = reg_log.predict(probs)"
      ],
      "metadata": {
        "id": "TabSWOESSdCV"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score(y_train, ypred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ExiDax7MQBi",
        "outputId": "11325322-7342-446b-ca13-f4fdb7a9bc21"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão: 80.6%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8060482688119472"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E9XyjSeUQ3J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validando o modelo\n",
        "\n",
        "reg_log = regLogistica(learning_rate=0.0005, num_steps=20, limiar=0.9, info=False)\n",
        "reg_log.fit(X_test, y_test)"
      ],
      "metadata": {
        "id": "YAW1D2tNT9Lk"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_probs = reg_log.predict_proba(X_test)\n",
        "test_predict = reg_log.predict(test_probs)"
      ],
      "metadata": {
        "id": "-AJQ3g-oUziR"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score(y_test, test_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_86J7i6ULJR",
        "outputId": "a6fd3edd-77c2-4d15-f0aa-c1c0c8fb882c"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão: 78.04%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7803793388424461"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hTJyvAhVUxVW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}