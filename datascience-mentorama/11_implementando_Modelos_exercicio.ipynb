{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_implementando_Modelos_exercicio.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjyyIbj65klsEBa6pOOMhj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eutiagovski/projetos-cursos/blob/main/datascience-mentorama/11_implementando_Modelos_exercicio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "OUrhn64Z1Kv5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_friedman1, make_classification\n",
        "from sklearn.base import BaseEstimator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Funções dos exercícios\n",
        "\n",
        "def getData():\n",
        "  X, y = make_friedman1(n_samples=10000, n_features=5, noise=0.5, random_state=0)\n",
        "  return X, y\n",
        "\n",
        "def getData2():\n",
        "  X, y = make_classification(n_classes=2, n_features=5, n_samples=10000, random_state=0)\n",
        "  return X, y\n",
        "\n",
        "# Classe regressão linear criada em aula\n",
        "\n",
        "class regLinear(BaseEstimator):\n",
        "  def __init__(self, learning_rate, num_steps):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_steps = num_steps\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    y = y.reshape(-1, 1)\n",
        "    m = X.shape[0]\n",
        "    k = X.shape[1]\n",
        "    theta = np.random.randn(k + 1, 1)\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "\n",
        "    for step in range(self.num_steps):\n",
        "      gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
        "      theta = theta - self.learning_rate * gradients\n",
        "\n",
        "    self.final_theta = theta\n",
        "    print('Model trained')\n",
        "\n",
        "  def predict(self, X):\n",
        "    m = X.shape[0]\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "    preds = X_b.dot(self.final_theta)\n",
        "    return preds.reshape(-1,)"
      ],
      "metadata": {
        "id": "xsAFj1N912az"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 1: Regressão Linear:"
      ],
      "metadata": {
        "id": "gG-beKFvFtJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parte 1\n",
        "\n",
        "1- Usando a função getData(), carregue os dados disponibilizados.\n",
        "\n",
        "2- Separe parte dos dados para o dataset de teste.\n",
        "\n",
        "3- Usando a metodologia de validação cruzada, teste diferentes parâmetros da regLinear - diferentes learning_rates e num_steps - para escolher a melhor combinação de parâmetros.\n",
        "\n",
        "4- Implemente a regressão linear do scikit-learn e compare os resultados obtidos.\n"
      ],
      "metadata": {
        "id": "yfsaZ9QB5mun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando os dados do exercicio\n",
        "\n",
        "X, y = getData()\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3AuKc0xikpA",
        "outputId": "961a34d8-c17b-4293-ac50-a104d1aeeb45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 5), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seprando os dados em treino e teste\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "doIaB0YOiteN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain.shape, Xtest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIsj3BRo5_Wr",
        "outputId": "3fd765f0-a116-4819-9a4a-be28c4ab74bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7500, 5), (2500, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## teste de caso:\n",
        "\n",
        "lin_reg = regLinear(num_steps=1, learning_rate=0.25)\n",
        "lin_reg.fit(Xtrain, ytrain)\n",
        "\n",
        "ypred = lin_reg.predict(Xtest)\n",
        "ypred, ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-k_-xGKlZ5u",
        "outputId": "6bb954df-ce72-499e-b0f0-0f6cd16239f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([18.00688701, 18.85258444, 13.10094613, ..., 19.95638332,\n",
              "        17.21678979, 12.38755867]),\n",
              " array([15.45130146, 17.53678595, 11.80968997, ..., 21.49622573,\n",
              "        23.10941602,  6.7219856 ]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "lin_mse = mean_squared_error(ytest, ypred)\n",
        "lin_mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFA5r_u1mi5F",
        "outputId": "620af36d-0cb3-4b46-87fe-8c57b62c0560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.197130150685894"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [1, 3, 5, 10, 100, 200]\n",
        "rates = [0.0025, 0.025, 0.5, 0.75, 1, 1.25]\n",
        "\n",
        "for rate in rates:\n",
        " for step in steps:\n",
        "    lin_reg = regLinear(num_steps=step, learning_rate=rate)\n",
        "    lin_reg.fit(Xtrain, ytrain)\n",
        "\n",
        "    ypred = lin_reg.predict(Xtrain)\n",
        "    lin_mse = mean_squared_error(ytrain, ypred)\n",
        "\n",
        "    print(f'Step: {step}')\n",
        "    print(f'Learning Rate: {rate}')\n",
        "    print(f'Mse: {mean_squared_error(ytrain, ypred)}')\n",
        "    print()        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv8epVSktvRV",
        "outputId": "315c079a-bfa4-435e-e2cb-17af293df2cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.0025\n",
            "Mse: 309.4838759888438\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.0025\n",
            "Mse: 205.49146380994694\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.0025\n",
            "Mse: 245.8049687641348\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.0025\n",
            "Mse: 165.6926847456548\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.0025\n",
            "Mse: 29.898416271347134\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.0025\n",
            "Mse: 12.732022328216072\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.025\n",
            "Mse: 141.47931055576552\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.025\n",
            "Mse: 96.20595140201569\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.025\n",
            "Mse: 79.44128557388879\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.025\n",
            "Mse: 32.64070114057634\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.025\n",
            "Mse: 10.162098142399824\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.025\n",
            "Mse: 8.307114916190125\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.5\n",
            "Mse: 367.48462134149895\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.5\n",
            "Mse: 1293.9941828909894\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.5\n",
            "Mse: 3852.2733942861437\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.5\n",
            "Mse: 25066.193149041457\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.5\n",
            "Mse: 3.179154639915253e+24\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.5\n",
            "Mse: 5.213402794667623e+46\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.75\n",
            "Mse: 1301.641264219731\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.75\n",
            "Mse: 34259.58609564888\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.75\n",
            "Mse: 1357133.6681131474\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.75\n",
            "Mse: 9823561004.798317\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.75\n",
            "Mse: 5.6077486027986835e+79\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.75\n",
            "Mse: 8.498369656900334e+156\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 1\n",
            "Mse: 3023.791729285288\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 1\n",
            "Mse: 484699.8972405381\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 1\n",
            "Mse: 69552924.7546767\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 1\n",
            "Mse: 20711540921915.617\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 1\n",
            "Mse: 1.062119039247911e+113\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 1\n",
            "Mse: 6.714263567949843e+223\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 1.25\n",
            "Mse: 5319.221578777608\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 1.25\n",
            "Mse: 2089701.2987708817\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 1.25\n",
            "Mse: 1478064440.4101171\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 1.25\n",
            "Mse: 7108245448576384.0\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 1.25\n",
            "Mse: 1.6223601228035065e+137\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 1.25\n",
            "Mse: 1.6901951012520327e+272\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Melhores parâmetros para o modelo\n",
        "\n",
        "lin_reg = regLinear(num_steps=200, learning_rate=0.75)\n",
        "\n",
        "lin_reg.fit(Xtrain, ytrain)\n",
        "ypred = lin_reg.predict(Xtrain)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytrain, ypred)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-xWcmFdwv0i",
        "outputId": "17141673-bec9-4122-8166-e91d0bf6a0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "MSE: 1.2916552867579406e+157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def display_scores(scores):\n",
        "  scores = np.sqrt(-scores)\n",
        "  print('\\nCross Val Scores: \\n')\n",
        "  print(f'Mean: {scores.mean()}')\n",
        "  print(f'Std Deriv: {scores.std()}')\n",
        "  print(f'Scores: {scores}')\n",
        "\n",
        "\n",
        "lin_reg_score = cross_val_score(lin_reg, Xtrain, ytrain, scoring='neg_mean_squared_error', cv=10)\n",
        "lin_reg_score = (display_scores(lin_reg_score))\n",
        "lin_reg_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZeW9A9pAxkd",
        "outputId": "754d87d9-35d3-43cd-bb53-671b01ac2402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "\n",
            "Cross Val Scores: \n",
            "\n",
            "Mean: 3.280193110058267e+78\n",
            "Std Deriv: 1.0810859544322886e+78\n",
            "Scores: [3.84986333e+78 3.02129004e+78 3.06390867e+78 5.60377658e+78\n",
            " 2.91782018e+78 3.93272849e+78 3.75498654e+78 1.56090776e+78\n",
            " 1.82709515e+78 3.26955435e+78]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparando com o modelo do sklearn\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "lin_reg.fit(Xtrain, ytrain)\n",
        "\n",
        "ypred = lin_reg.predict(Xtrain)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytrain, ypred)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7iMGXxAumZZ",
        "outputId": "ba486d97-0125-4c65-ec08-69eaab87a750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 6.029690122877917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg_score_sk = cross_val_score(lin_reg, Xtrain, ytrain, scoring='neg_mean_squared_error', cv=10)\n",
        "lin_reg_score_sk = (display_scores(lin_reg_score_sk))\n",
        "lin_reg_score_sk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0_UPvhkA1Br",
        "outputId": "009f1c52-56f6-4d1e-a89a-1153658bf6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross Val Scores: \n",
            "\n",
            "Mean: 2.456534270989073\n",
            "Std Deriv: 0.06368699377445314\n",
            "Scores: [2.47657636 2.37781191 2.55254157 2.53673673 2.37051872 2.43215304\n",
            " 2.46349076 2.37140731 2.5078694  2.47623693]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validando no conjunto de testes:\n",
        "\n",
        "lin_reg = regLinear(num_steps=200, learning_rate=0.75)\n",
        "\n",
        "lin_reg.fit(Xtest, ytest)\n",
        "ypred = lin_reg.predict(Xtest)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytest, ypred)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKD6SWu84EqZ",
        "outputId": "7d01836c-21aa-4860-c6e7-d467ce1ac8ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "MSE: 3.2433479842039236e+155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg_score_ts = cross_val_score(lin_reg, Xtrain, ytrain, scoring='neg_mean_squared_error', cv=10)\n",
        "lin_reg_score_ts = (display_scores(lin_reg_score_ts))\n",
        "lin_reg_score_ts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBRwpYOCA1wz",
        "outputId": "fbc3ddaa-204d-40d1-9b7c-d59b41860446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "\n",
            "Cross Val Scores: \n",
            "\n",
            "Mean: 3.367501170044973e+78\n",
            "Std Deriv: 1.2458606442298073e+78\n",
            "Scores: [3.52099453e+78 4.08938651e+78 3.16751243e+78 6.24124646e+78\n",
            " 3.09738265e+78 3.82007450e+78 3.03484790e+78 1.57866326e+78\n",
            " 1.61534926e+78 3.50955422e+78]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parte 2\n",
        "Introdução__\n",
        "\n",
        "Para cada variável explicativa $X_1, .., X_5$, crie outras variáveis usando o __quadrado__ de cada um delas. Desta forma, o conjunto final será de 10 variáveis, em que:\n",
        "\n",
        "$X_6 = (X_1)^{2}$, $X_7 = (X_2)^{2}$, $X_8 = (X_3)^{2}$, $X_9 = (X_4)^{2}$, $X_{10} = (X_5)^{2}$.\n",
        "\n",
        "Ao treinarmos uma regressão linear com essas 10 variáveis, a predição é da forma:\n",
        "\n",
        "$y_{pred} = \\theta_0 + \\theta_1 \\cdot X_1 + .. + \\theta_5 \\cdot X_5 + \\theta_6 \\cdot (X_1)^{2} + .. + \\theta_{10} \\cdot (X_5)^{2}$\n",
        "\n",
        "Como estamos usando o quadrado das variáveis explicativas, dizemos que temos um __modelo de regressão polinomial de grau 2__. Podemos ter variações deste modelo:\n",
        "\n",
        "-Podemos aumentar o grau: basta mudar a potência que elevamos as variáveis. Por exemplo, podemos incluir o __cubo__ das variáveis e termos um modelo polinomial de ordem 3.\n",
        "\n",
        "-Podemos ter __interações__ entre as variáveis: multiplicações entre as variáveis.\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "$y_{pred} = \\theta_0 + \\theta_1 \\cdot X_1 + .. + \\theta_5 \\cdot X_5 + \\theta_6 \\cdot (X_1)^{2} + .. + \\theta_{10} \\cdot (X_5)^{2} + \\theta_{11} \\cdot (X_1)^{3} + \\theta_{12} \\cdot V1 + \\theta_{13} \\cdot V2$,\n",
        "\n",
        "onde\n",
        "\n",
        "$V_1 = X_1 \\cdot X_2$ e $V_2 = (X_2)^{2} \\cdot X_4$\n",
        "\n",
        "Exercício__\n",
        "\n",
        "1- Estude o link:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
        "\n",
        "em que é discutido como criar modelos polinomiais com o scikit-learn de forma detalhada.\n",
        "\n",
        "2- Repita os passos da primeira parte, mas agora considerando polinômios de graus 2 ou mais.\n",
        "\n",
        "3- Inclua regularização Ridge e Lasso nas análises e teste os resultados para diferentes parâmetros $\\alpha$.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "DrxzILCd0g9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# realizando o quadrado das variáveis X\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly_features.fit_transform(Xtrain)\n",
        "X_poly.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtapvzH1yls5",
        "outputId": "c0aad09e-5d48-4fa6-af1e-ff920ead21d8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7500, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_poly[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdveHFET3AoE",
        "outputId": "fcb92a48-8624-4e11-b057-2507054916a8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.31297196e-01, 4.85914587e-01, 2.85904707e-01, 8.73865682e-01,\n",
              "        4.58547122e-02, 1.72389537e-02, 6.37992229e-02, 3.75384865e-02,\n",
              "        1.14736114e-01, 6.02059515e-03, 2.36112986e-01, 1.38925268e-01,\n",
              "        4.24624082e-01, 2.22814736e-02, 8.17415017e-02, 2.49842312e-01,\n",
              "        1.31100781e-02, 7.63641230e-01, 4.00708594e-02, 2.10265463e-03],\n",
              "       [9.61526016e-01, 1.13272056e-01, 7.64526683e-01, 4.05853991e-01,\n",
              "        3.78209558e-02, 9.24532279e-01, 1.08914029e-01, 7.35112295e-01,\n",
              "        3.90239171e-01, 3.63658330e-02, 1.28305586e-02, 8.65995091e-02,\n",
              "        4.59719160e-02, 4.28405742e-03, 5.84501049e-01, 3.10286206e-01,\n",
              "        2.89151299e-02, 1.64717462e-01, 1.53497859e-02, 1.43042470e-03],\n",
              "       [6.59939163e-01, 2.37834967e-01, 7.90825285e-01, 4.10507602e-01,\n",
              "        6.90591370e-01, 4.35519699e-01, 1.56956609e-01, 5.21896577e-01,\n",
              "        2.70910043e-01, 4.55748291e-01, 5.65654716e-02, 1.88085906e-01,\n",
              "        9.76330620e-02, 1.64246776e-01, 6.25404632e-01, 3.24639791e-01,\n",
              "        5.46137117e-01, 1.68516491e-01, 2.83493007e-01, 4.76916440e-01],\n",
              "       [9.65734670e-01, 4.71723000e-01, 2.52429466e-02, 9.97889449e-01,\n",
              "        4.25877816e-01, 9.32643452e-01, 4.55559256e-01, 2.43779887e-02,\n",
              "        9.63696438e-01, 4.11284972e-01, 2.22522589e-01, 1.19076785e-02,\n",
              "        4.70727405e-01, 2.00896361e-01, 6.37206355e-04, 2.51896701e-02,\n",
              "        1.07504110e-02, 9.95783353e-01, 4.24978979e-01, 1.81371914e-01],\n",
              "       [1.78865807e-01, 4.89663038e-02, 6.04644909e-01, 1.43858392e-01,\n",
              "        5.76221135e-02, 3.19929770e-02, 8.75839746e-03, 1.08150300e-01,\n",
              "        2.57313474e-02, 1.03066258e-02, 2.39769891e-03, 2.96072263e-02,\n",
              "        7.04421374e-03, 2.82154191e-03, 3.65595466e-01, 8.69832445e-02,\n",
              "        3.48409175e-02, 2.06952370e-02, 8.28942460e-03, 3.32030796e-03],\n",
              "       [2.28208886e-01, 1.00485921e-01, 1.83985157e-01, 7.93433796e-01,\n",
              "        3.67885534e-01, 5.20792958e-02, 2.29317800e-02, 4.19870478e-02,\n",
              "        1.81068643e-01, 8.39547481e-02, 1.00974202e-02, 1.84879179e-02,\n",
              "        7.97289254e-02, 3.69673166e-02, 3.38505381e-02, 1.45980042e-01,\n",
              "        6.76854779e-02, 6.29537188e-01, 2.91892816e-01, 1.35339766e-01],\n",
              "       [9.93941642e-01, 1.73853000e-01, 1.35848655e-01, 1.36761776e-01,\n",
              "        7.91105317e-01, 9.87919988e-01, 1.72799737e-01, 1.35025635e-01,\n",
              "        1.35933225e-01, 7.86312517e-01, 3.02248658e-02, 2.36176963e-02,\n",
              "        2.37764452e-02, 1.37536033e-01, 1.84548570e-02, 1.85789034e-02,\n",
              "        1.07470593e-01, 1.87037835e-02, 1.08192968e-01, 6.25847622e-01],\n",
              "       [5.94110940e-01, 9.41736775e-03, 1.44800668e-01, 3.25931260e-01,\n",
              "        8.76819618e-02, 3.52967808e-01, 5.59496120e-03, 8.60276612e-02,\n",
              "        1.93639327e-01, 5.20928127e-02, 8.86868154e-05, 1.36364115e-03,\n",
              "        3.06941454e-03, 8.25733280e-04, 2.09672336e-02, 4.71950643e-02,\n",
              "        1.26964067e-02, 1.06231186e-01, 2.85782923e-02, 7.68812643e-03],\n",
              "       [3.26046195e-01, 5.42267332e-01, 8.52975116e-01, 5.27120081e-01,\n",
              "        7.54086363e-01, 1.06306121e-01, 1.76804200e-01, 2.78109291e-01,\n",
              "        1.71865497e-01, 2.45866989e-01, 2.94053859e-01, 4.62540540e-01,\n",
              "        2.85840000e-01, 4.08916400e-01, 7.27566549e-01, 4.49620312e-01,\n",
              "        6.43216903e-01, 2.77855580e-01, 3.97494065e-01, 5.68646243e-01],\n",
              "       [6.91684436e-01, 7.14852344e-01, 2.52410918e-02, 4.51247107e-01,\n",
              "        1.84208867e-01, 4.78427359e-01, 4.94452241e-01, 1.74588704e-02,\n",
              "        3.12120601e-01, 1.27414406e-01, 5.11013874e-01, 1.80436537e-02,\n",
              "        3.22575052e-01, 1.31682140e-01, 6.37112717e-04, 1.13899697e-02,\n",
              "        4.64963292e-03, 2.03623952e-01, 8.31237183e-02, 3.39329066e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testando no modelo de rgressão do sklearn\n",
        "\n",
        "poly_fit = LinearRegression()\n",
        "poly_fit.fit(X_poly, ytrain)\n",
        "\n",
        "y_new = poly_fit.predict(X_poly)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytrain, y_new)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjBBY_MP3RH5",
        "outputId": "cc823ae0-9fe9-4c8d-c2cf-3be88ad33c10"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 2.002282162883313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly_reg_score = cross_val_score(poly_fit, X_poly, ytrain, scoring='neg_mean_squared_error', cv=10)\n",
        "poly_reg_score = (display_scores(poly_reg_score))\n",
        "poly_reg_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVOzG8EBA9JM",
        "outputId": "317acc98-0e71-42ec-a65b-c8978ee1743e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross Val Scores: \n",
            "\n",
            "Mean: 1.4193233715978346\n",
            "Std Deriv: 0.03591524474879628\n",
            "Scores: [1.36414742 1.3896057  1.4553139  1.44598499 1.45234123 1.36845277\n",
            " 1.38782802 1.43485399 1.46289158 1.43181413]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testando no modelo consolidado de regressão linear\n",
        "\n",
        "poly_fit = regLinear(num_steps=200, learning_rate=0.75)\n",
        "poly_fit.fit(X_poly, ytrain)\n",
        "\n",
        "y_new = poly_fit.predict(X_poly)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytrain, y_new)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07UrLpc83cDZ",
        "outputId": "f0ca7420-5704-426a-e643-dddf63d070ca"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "MSE: 1.0733365390934909e+262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly_reg_score = cross_val_score(poly_fit, X_poly, ytrain, scoring='neg_mean_squared_error', cv=10)\n",
        "poly_reg_score = (display_scores(poly_reg_score))\n",
        "poly_reg_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRryBIICBAa0",
        "outputId": "6fbc18f5-2828-4b2f-bd20-4e7de1de883b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "\n",
            "Cross Val Scores: \n",
            "\n",
            "Mean: 1.1131105396972681e+131\n",
            "Std Deriv: 5.213320645481129e+130\n",
            "Scores: [1.32539853e+131 1.49814882e+131 7.98534513e+130 2.32035136e+131\n",
            " 9.75998888e+130 1.07622446e+131 1.04120657e+131 4.32419889e+130\n",
            " 4.30922183e+130 1.23190018e+131]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## procurando o melhor parâmetro\n",
        "\n",
        "steps = [1, 3, 5, 10, 100, 200]\n",
        "rates = [0.0025, 0.025, 0.5, 0.75, 1, 1.25]\n",
        "\n",
        "for rate in rates:\n",
        "  for step in steps:\n",
        "      lin_reg = regLinear(num_steps=step, learning_rate=rate)\n",
        "      lin_reg.fit(X_poly, ytrain)\n",
        "\n",
        "      ypred = lin_reg.predict(X_poly)\n",
        "      lin_mse = mean_squared_error(ytrain, ypred)\n",
        "\n",
        "      print(f'Step: {step}')\n",
        "      print(f'Learning Rate: {rate}')\n",
        "      print(f'Mse: {mean_squared_error(ytrain, ypred)}')\n",
        "      print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vj_hQbF4IhC",
        "outputId": "94b3aaa2-06e1-4b2b-deb5-59c35932f1e3"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.0025\n",
            "Mse: 263.24369053972697\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.0025\n",
            "Mse: 211.52700937062687\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.0025\n",
            "Mse: 286.59470220776956\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.0025\n",
            "Mse: 104.021656326064\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.0025\n",
            "Mse: 14.266364096259215\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.0025\n",
            "Mse: 10.41600669400927\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.025\n",
            "Mse: 119.39338814585622\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.025\n",
            "Mse: 59.43690552281012\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.025\n",
            "Mse: 35.5904947019083\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.025\n",
            "Mse: 15.02040940671429\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.025\n",
            "Mse: 7.138380614275067\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.025\n",
            "Mse: 6.272269653344616\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.5\n",
            "Mse: 754.515063001814\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.5\n",
            "Mse: 60258.65466092153\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.5\n",
            "Mse: 4140859.661624539\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.5\n",
            "Mse: 72305126455.3546\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.5\n",
            "Mse: 3.5533410229273105e+86\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.5\n",
            "Mse: 6.511577391494143e+170\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 0.75\n",
            "Mse: 5452.7978618373045\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 0.75\n",
            "Mse: 1824517.2206136973\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 0.75\n",
            "Mse: 721125915.6751677\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 0.75\n",
            "Mse: 2521176517543796.0\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 0.75\n",
            "Mse: 1.2276708266202456e+132\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 0.75\n",
            "Mse: 6.853663546611529e+261\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 1\n",
            "Mse: 10015.158794584671\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 1\n",
            "Mse: 15540512.916628903\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 1\n",
            "Mse: 23912897799.43955\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 1\n",
            "Mse: 1.922859026505392e+18\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 1\n",
            "Mse: 6.448395738439747e+161\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 1\n",
            "Mse: inf\n",
            "\n",
            "Model trained\n",
            "Step: 1\n",
            "Learning Rate: 1.25\n",
            "Mse: 10981.460095599943\n",
            "\n",
            "Model trained\n",
            "Step: 3\n",
            "Learning Rate: 1.25\n",
            "Mse: 111320120.24637516\n",
            "\n",
            "Model trained\n",
            "Step: 5\n",
            "Learning Rate: 1.25\n",
            "Mse: 327151902553.2197\n",
            "\n",
            "Model trained\n",
            "Step: 10\n",
            "Learning Rate: 1.25\n",
            "Mse: 3.101541008879462e+20\n",
            "\n",
            "Model trained\n",
            "Step: 100\n",
            "Learning Rate: 1.25\n",
            "Mse: 1.2132566552519062e+184\n",
            "\n",
            "Model trained\n",
            "Step: 200\n",
            "Learning Rate: 1.25\n",
            "Mse: inf\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n",
            "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n",
            "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n",
            "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n",
            "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consolidando os melhores parâmetros: \n",
        "\n",
        "lin_reg_poly_best = regLinear(learning_rate=0.5, num_steps=100)\n",
        "lin_reg_poly_best.fit(X_poly, ytrain)\n",
        "\n",
        "y_new = lin_reg_poly_best.predict(X_poly)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytrain, y_new)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_7xauQT5p49",
        "outputId": "48ee6d93-390d-4760-d964-2bb258073b45"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "MSE: 4.0148074059523346e+86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly_reg_score = cross_val_score(lin_reg_poly_best, X_poly, ytrain, scoring='neg_mean_squared_error', cv=10)\n",
        "poly_reg_score = (display_scores(poly_reg_score))\n",
        "poly_reg_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO2Q7pfNBFBk",
        "outputId": "269327cc-a450-4f92-ccd9-c593232b620d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "\n",
            "Cross Val Scores: \n",
            "\n",
            "Mean: 2.0630565969996695e+43\n",
            "Std Deriv: 5.292274891405337e+42\n",
            "Scores: [2.01566053e+43 2.37721533e+43 2.07463496e+43 2.97137075e+43\n",
            " 2.21702267e+43 2.54589889e+43 2.15741950e+43 1.20722563e+43\n",
            " 1.13671334e+43 1.92740437e+43]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validando no conjunto de testes:\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly_test = poly_features.fit_transform(Xtest)\n",
        "\n",
        "lin_reg_poly_best = regLinear(learning_rate=0.5, num_steps=100)\n",
        "lin_reg_poly_best.fit(X_poly_test, ytest)\n",
        "\n",
        "y_new = lin_reg_poly_best.predict(X_poly_test)\n",
        "\n",
        "print(f'MSE: {mean_squared_error(ytest, y_new)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKhOjW1Q6DQq",
        "outputId": "5cdfd1ee-dee4-4792-f6e6-da16d8a8d5ce"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "MSE: 1.691610819784281e+85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ply_reg_test_score = cross_val_score(lin_reg_poly_best, X_poly_test, ytest, scoring='neg_mean_squared_error', cv=10)\n",
        "ply_reg_test_score = (display_scores(ply_reg_test_score))\n",
        "ply_reg_test_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mc9zRowBJn2",
        "outputId": "5a6594a3-6f62-4063-f855-1d5b7bcf53ff"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "\n",
            "Cross Val Scores: \n",
            "\n",
            "Mean: 4.2484327893225244e+42\n",
            "Std Deriv: 2.107908393154258e+42\n",
            "Scores: [4.77306777e+42 2.47063995e+42 6.03591994e+42 2.92457218e+42\n",
            " 1.36446259e+42 6.98577308e+42 2.66395901e+42 3.89432892e+42\n",
            " 8.28108130e+42 3.09052315e+42]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def polyFit(X, y, grau):\n",
        "  poylbig_features = PolynomialFeatures(degree=grau, include_bias=False)\n",
        "  std_scaler = StandardScaler()\n",
        "  lin_reg = regLinear(learning_rate=0.5, num_steps=100)\n",
        "\n",
        "  polynomial_regressor = Pipeline([\n",
        "                                   ('poly_features', poylbig_features),\n",
        "                                   ('std_scaler', std_scaler),\n",
        "                                   ('lin_reg', lin_reg),\n",
        "  ])\n",
        "\n",
        "  polynomial_regressor.fit(X, y)\n",
        "  return polynomial_regressor"
      ],
      "metadata": {
        "id": "Has1rpS28WBM"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for grau in [1,2,3,4]:\n",
        "  print()\n",
        "\n",
        "  polyfit = polyFit(Xtrain, ytrain, grau)\n",
        "\n",
        "  ypoly = polyfit.predict(Xtrain)\n",
        "\n",
        "  print(f'Grau: {grau}')\n",
        "  print(f'MSE: {mean_squared_error(ytrain, ypoly)}')\n",
        "  print('-' * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc4vRgPA8bk7",
        "outputId": "5f692a62-40ea-4ea8-b2aa-61d6e0c78c7e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model trained\n",
            "Grau: 1\n",
            "MSE: 6.029690122877917\n",
            "------------------------------------------------------------\n",
            "\n",
            "Model trained\n",
            "Grau: 2\n",
            "MSE: 1.9929608322759157e+131\n",
            "------------------------------------------------------------\n",
            "\n",
            "Model trained\n",
            "Grau: 3\n",
            "MSE: 2.17292460452633e+245\n",
            "------------------------------------------------------------\n",
            "\n",
            "Model trained\n",
            "Grau: 4\n",
            "MSE: inf\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:427: RuntimeWarning: overflow encountered in square\n",
            "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regressão poly Ridge\n",
        "\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "def polyFitReg(X, y, grau, base_model, base_model_name):\n",
        "  poylbig_features = PolynomialFeatures(degree=grau, include_bias=False)\n",
        "  std_scaler = StandardScaler()\n",
        "  basemodel = base_model\n",
        "\n",
        "  polynomial_regressor = Pipeline([\n",
        "                                   ('poly_features', poylbig_features),\n",
        "                                   ('std_scaler', std_scaler),\n",
        "                                   (base_model_name, basemodel),\n",
        "  ])\n",
        "\n",
        "  polynomial_regressor.fit(X, y)\n",
        "  return polynomial_regressor\n",
        "\n",
        "grau = 3\n",
        "\n",
        "for alpha in [0, 0.001, 0.01, 1, 10, 100, 10000]:\n",
        "  model_name = 'Ridge_alpha: ' + str(alpha)\n",
        "  polyfit = polyFitReg(Xtrain,\n",
        "                       ytrain, \n",
        "                       grau, \n",
        "                       base_model = Ridge(alpha=alpha),\n",
        "                       base_model_name = model_name)\n",
        "  \n",
        "  ypoly_novo = polyfit.predict(Xtest)\n",
        "\n",
        "  print(model_name)\n",
        "\n",
        "  train_error = mean_squared_error(ytrain, polyfit.predict(Xtrain))\n",
        "  test_error = mean_squared_error(ytest, polyfit.predict(Xtest))\n",
        "\n",
        "  print(f'MSE (treino): {train_error}')\n",
        "  print(f'MSE (teste): {test_error}')\n",
        "\n",
        "  print(f'{train_error-test_error*-1}')\n",
        "\n",
        "  print('-' * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7LQ_VpO87T-",
        "outputId": "1c78a5fc-fe8f-4a63-fa51-05acb1f00554"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge_alpha: 0\n",
            "MSE (treino): 0.3383871229994836\n",
            "MSE (teste): 0.34448180034016745\n",
            "0.682868923339651\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 0.001\n",
            "MSE (treino): 0.33838713035803825\n",
            "MSE (teste): 0.3444802568647313\n",
            "0.6828673872227695\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 0.01\n",
            "MSE (treino): 0.33838785693252776\n",
            "MSE (teste): 0.3444669954653998\n",
            "0.6828548523979275\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 1\n",
            "MSE (treino): 0.3440682641862712\n",
            "MSE (teste): 0.34836651154433657\n",
            "0.6924347757306077\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 10\n",
            "MSE (treino): 0.510568120906315\n",
            "MSE (teste): 0.4992457998982876\n",
            "1.0098139208046026\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 100\n",
            "MSE (treino): 1.3433908078430647\n",
            "MSE (teste): 1.3226150165814976\n",
            "2.6660058244245626\n",
            "------------------------------------------------------------\n",
            "Ridge_alpha: 10000\n",
            "MSE (treino): 6.904937718169202\n",
            "MSE (teste): 7.4852111782435\n",
            "14.3901488964127\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Regressão Poly Lasso\n",
        "\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "def polyFitReg(X, y, grau, base_model, base_model_name):\n",
        "  poylbig_features = PolynomialFeatures(degree=grau, include_bias=False)\n",
        "  std_scaler = StandardScaler()\n",
        "  basemodel = base_model\n",
        "\n",
        "  polynomial_regressor = Pipeline([\n",
        "                                   ('poly_features', poylbig_features),\n",
        "                                   ('std_scaler', std_scaler),\n",
        "                                   (base_model_name, basemodel),\n",
        "  ])\n",
        "\n",
        "  polynomial_regressor.fit(X, y)\n",
        "  return polynomial_regressor\n",
        "\n",
        "grau = 3\n",
        "\n",
        "for alpha in [0.0001, 0.001, 0.01, 1, 10, 100, 10000]:\n",
        "  model_name = 'Lasso_alpha: ' + str(alpha)\n",
        "  polyfit = polyFitReg(Xtrain,\n",
        "                       ytrain, \n",
        "                       grau, \n",
        "                       base_model = Lasso(alpha=alpha),\n",
        "                       base_model_name = model_name)\n",
        "  \n",
        "  ypoly_novo = polyfit.predict(Xtrain)\n",
        "\n",
        "  print(model_name)\n",
        "\n",
        "  train_error = mean_squared_error(ytrain, polyfit.predict(Xtrain))\n",
        "  test_error = mean_squared_error(ytest, polyfit.predict(Xtest))\n",
        "\n",
        "  print(f'MSE (treino): {train_error}')\n",
        "  print(f'MSE (teste): {test_error}')\n",
        "\n",
        "  print(f'{train_error-test_error*-1}')\n",
        "\n",
        "  print('-' * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVDnASFsEbKu",
        "outputId": "39a32be6-2a2a-4d29-bfc1-8d87b0ed7df3"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e+03, tolerance: 1.818e+01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso_alpha: 0.0001\n",
            "MSE (treino): 0.5306273409253665\n",
            "MSE (teste): 0.5377499918989795\n",
            "1.068377332824346\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.048e+03, tolerance: 1.818e+01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso_alpha: 0.001\n",
            "MSE (treino): 0.4787696536311609\n",
            "MSE (teste): 0.4859672102473506\n",
            "0.9647368638785115\n",
            "------------------------------------------------------------\n",
            "Lasso_alpha: 0.01\n",
            "MSE (treino): 0.5382080650645861\n",
            "MSE (teste): 0.5334770412947463\n",
            "1.0716851063593325\n",
            "------------------------------------------------------------\n",
            "Lasso_alpha: 1\n",
            "MSE (treino): 9.158016773392355\n",
            "MSE (teste): 9.795678048590501\n",
            "18.953694821982857\n",
            "------------------------------------------------------------\n",
            "Lasso_alpha: 10\n",
            "MSE (treino): 24.24325135286504\n",
            "MSE (teste): 24.383883943845145\n",
            "48.627135296710186\n",
            "------------------------------------------------------------\n",
            "Lasso_alpha: 100\n",
            "MSE (treino): 24.24325135286504\n",
            "MSE (teste): 24.383883943845145\n",
            "48.627135296710186\n",
            "------------------------------------------------------------\n",
            "Lasso_alpha: 10000\n",
            "MSE (treino): 24.24325135286504\n",
            "MSE (teste): 24.383883943845145\n",
            "48.627135296710186\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.929e+01, tolerance: 1.818e+01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "\n",
        "def polyFitReg(X, y, grau, base_model, base_model_name):\n",
        "  poylbig_features = PolynomialFeatures(degree=grau, include_bias=False)\n",
        "  std_scaler = StandardScaler()\n",
        "  basemodel = base_model\n",
        "\n",
        "  polynomial_regressor = Pipeline([\n",
        "                                   ('poly_features', poylbig_features),\n",
        "                                   ('std_scaler', std_scaler),\n",
        "                                   (base_model_name, basemodel),\n",
        "  ])\n",
        "\n",
        "  polynomial_regressor.fit(X, y)\n",
        "  return polynomial_regressor\n",
        "\n",
        "grau = 3\n",
        "\n",
        "for alpha in [0.0001, 0.001, 0.01, 1, 10, 100, 10000]:\n",
        "  model_name = 'Lasso_alpha: ' + str(alpha)\n",
        "  polyfit = polyFitReg(Xtrain,\n",
        "                       ytrain, \n",
        "                       grau, \n",
        "                       base_model = ElasticNet(alpha=alpha, l1_ratio=0.5),\n",
        "                       base_model_name = model_name)\n",
        "  \n",
        "  ypoly_novo = polyfit.predict(Xtrain)\n",
        "\n",
        "  print(model_name)\n",
        "\n",
        "  train_error = mean_squared_error(ytrain, polyfit.predict(Xtrain))\n",
        "  test_error = mean_squared_error(ytest, polyfit.predict(Xtest))\n",
        "\n",
        "  print(f'MSE (treino): {train_error}')\n",
        "  print(f'MSE (teste): {test_error}')\n",
        "\n",
        "  print(f'{train_error-test_error*-1}')\n",
        "\n",
        "  print('-' * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg3ClaIHGBi7",
        "outputId": "d37929a2-5925-4655-e99a-039d63fcb4f9"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+03, tolerance: 1.818e+01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso_alpha: 0.0001\n",
            "MSE (treino): 0.5244579587791703\n",
            "MSE (teste): 0.5305061683267995\n",
            "1.0549641271059698\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.542e+03, tolerance: 1.818e+01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso_alpha: 0.001\n",
            "MSE (treino): 0.46087149764200264\n",
            "MSE (teste): 0.4595160928179032\n",
            "0.9203875904599058\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.623e+01, tolerance: 1.818e+01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso_alpha: 0.01\n",
            "MSE (treino): 0.9741795380317108\n",
            "MSE (teste): 0.9602627957592007\n",
            "1.9344423337909116\n",
            "------------------------------------------------------------\n",
            "Lasso_alpha: 1\n",
            "MSE (treino): 7.850660796056347\n",
            "MSE (teste): 8.499339930359003\n",
            "16.35000072641535\n",
            "------------------------------------------------------------\n",
            "Lasso_alpha: 10\n",
            "MSE (treino): 24.24325135286504\n",
            "MSE (teste): 24.383883943845145\n",
            "48.627135296710186\n",
            "------------------------------------------------------------\n",
            "Lasso_alpha: 100\n",
            "MSE (treino): 24.24325135286504\n",
            "MSE (teste): 24.383883943845145\n",
            "48.627135296710186\n",
            "------------------------------------------------------------\n",
            "Lasso_alpha: 10000\n",
            "MSE (treino): 24.24325135286504\n",
            "MSE (teste): 24.383883943845145\n",
            "48.627135296710186\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly_scaler = Pipeline([\n",
        "                        ('poly_features', PolynomialFeatures(degree=3, include_bias=False)),\n",
        "                        ('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "X_train_poly_scaled = poly_scaler.fit_transform(Xtest)\n"
      ],
      "metadata": {
        "id": "pbXAlpQxM0PM"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg = regLinear(learning_rate=0.5, num_steps=100)\n",
        "lin_reg.fit(X_train_poly_scaled, ytest)\n",
        "\n",
        "scores = cross_val_score(lin_reg, X_train_poly_scaled, ytest, cv=10, scoring='neg_mean_squared_error')\n",
        "result = np.sqrt(-scores)\n",
        "result.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ct3zrS6T_2y",
        "outputId": "2c576131-1d2a-49af-da68-f47db648bf9d"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n",
            "Model trained\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8921509718723085e+121"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_reg = Lasso(alpha=0.001)\n",
        "\n",
        "\n",
        "scores = cross_val_score(lasso_reg, X_train_poly_scaled, ytest, cv=10, scoring='neg_mean_squared_error')\n",
        "result = np.sqrt(-scores)\n",
        "result.mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_LzJtzNUNTD",
        "outputId": "fddd0b4a-90f0-4885-b9ec-0804cde834a6"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.062e+02, tolerance: 5.453e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.017e+02, tolerance: 5.481e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.152e+02, tolerance: 5.459e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.992e+02, tolerance: 5.421e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.901e+02, tolerance: 5.522e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.769e+02, tolerance: 5.428e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.915e+02, tolerance: 5.494e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.061e+02, tolerance: 5.506e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.008e+02, tolerance: 5.523e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.988e+02, tolerance: 5.573e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7021425673585878"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 2: Regressão Logística:\n"
      ],
      "metadata": {
        "id": "xHT5Zg73GMhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parte 1\n",
        "\n",
        "Crie uma classe regLogistica para treinar o modelo de regressão logística. Essa classe deve ser usada para problemas de classificação binária, cuja variável target assume os valores: 0 (classe negativa) e 1 (classe positiva).\n",
        "\n",
        "O método construtor dessa classe deve possuir 3 parâmetros: learning_rate, num_steps e limiar.\n",
        "\n",
        "Os outros médotos devem ser:\n",
        "\n",
        "    - médoto fit: para treinar o modelo - usando gradient descent\n",
        "    \n",
        "    - médoto predict_proba: para retornar a probabilidade da classe 1\n",
        "    \n",
        "    - médoto predict: retornar a classe predita: 0 ou 1 - dependente do limiar\n",
        "    \n"
      ],
      "metadata": {
        "id": "z4PnCSFv6AIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class regLogistica(BaseEstimator):\n",
        "  def __init__(self, learning_rate=0.01, num_steps=10, limiar=0.8, info=False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_steps = num_steps\n",
        "    self.limiar = limiar\n",
        "    self.info = info\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    y = y.reshape(-1, 1)\n",
        "    # treinar o modelo segundo o método gradient descent\n",
        "    \n",
        "    # primeiro reshape os dados para o formato adequado\n",
        "    X_b = np.c_[np.ones(X.shape[0]), X]\n",
        "    theta = np.random.randn(X_b.shape[1], 1)\n",
        "\n",
        "    for step in range(self.num_steps):\n",
        "      #Calculando a probabilidade\n",
        "      yscores = (1 / (1 + np.exp(-X_b.dot(theta))))\n",
        "\n",
        "      #Calculando o gradiente do logloss\n",
        "      gradient = X_b.T.dot(yscores -y)\n",
        "\n",
        "      #Atualizando os pesos\n",
        "      theta = theta - self.learning_rate * gradient\n",
        "\n",
        "      #Calculando o logloss nos passos\n",
        "      self.logloss_step = ((y * np.log(yscores) + (1 - y) * np.log(1 - yscores)).mean() * -1)\n",
        "\n",
        "      #Printa as informações\n",
        "      if self.info:\n",
        "        print(f'Step: {step}')\n",
        "        print(f'Theta: {theta.reshape(-1,)}')\n",
        "        print(f'LogLoss: {self.logloss_step}')\n",
        "        print()\n",
        "        print('Model Trained!')\n",
        "        print('-' * 60)\n",
        "        print()\n",
        "\n",
        "      self.theta_final = theta\n",
        "\n",
        "  def predict(self, X):\n",
        "    self.ypred = np.where(X > self.limiar, 1, 0)\n",
        "    return self.ypred\n",
        "  \n",
        "  def predict_proba(self, X):\n",
        "    m = X.shape[0]\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "    probs = (X_b.dot(self.theta_final))\n",
        "    return probs\n"
      ],
      "metadata": {
        "id": "H0ZGc_JN4uZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parte 2\n",
        "\n",
        "Usando a função getData2(), carregue o dataset disponibilizado.\n",
        "\n",
        "Use a regLogistica, classe criada na parte 1 do exercício, para treinar modelos nestes dados. Use validação cruzada para seleção dos parâmetros. Considere diferentes métricas de classificação e justifique as escolhas.\n"
      ],
      "metadata": {
        "id": "AZ2VcGYRGQxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = getData2()\n",
        "X, y"
      ],
      "metadata": {
        "id": "IorX92dt1B6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d47f7a1-fd39-44d2-a91a-9b86ca353772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.82380715, -0.59163837,  0.13041933, -0.40345475,  1.16360785],\n",
              "        [ 0.7091986 ,  0.60606127, -0.37678226,  0.39654936, -1.15961369],\n",
              "        [ 1.61194498,  0.36486859,  1.91264129,  0.38601731, -0.31972146],\n",
              "        ...,\n",
              "        [ 1.38015938,  1.43125078, -1.42179351,  0.89985272, -0.70967569],\n",
              "        [-1.63030207, -0.23544436, -2.29968645, -0.32243952, -1.49535664],\n",
              "        [ 1.07627839,  1.178116  , -1.27826779,  0.73327205, -1.27906183]]),\n",
              " array([0, 1, 1, ..., 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_log = regLogistica(learning_rate=0.0001, num_steps=10, limiar=0.9, info=True)\n",
        "reg_log.fit(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-SBtCFBG7M_",
        "outputId": "847ca5c8-779d-4f22-b403-1cb34629547a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0\n",
            "Theta: [ 1.6368773   0.55419767  0.65963913  0.53650266 -1.96427246  2.30179449]\n",
            "LogLoss: 1.4392522469901945\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 1\n",
            "Theta: [ 1.43346586  0.53159113  0.52498652  0.86388505 -2.03560216  2.03639424]\n",
            "LogLoss: 1.086414380811293\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 2\n",
            "Theta: [ 1.25557412  0.52542086  0.4403946   1.08405542 -2.07941488  1.79777894]\n",
            "LogLoss: 0.8714401593430686\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 3\n",
            "Theta: [ 1.10107583  0.52890078  0.38906493  1.23069582 -2.10510221  1.58785682]\n",
            "LogLoss: 0.7406615580116819\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 4\n",
            "Theta: [ 0.96589911  0.53678385  0.35845947  1.32861716 -2.11969646  1.40353153]\n",
            "LogLoss: 0.6563525785354732\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 5\n",
            "Theta: [ 0.8466067   0.54607846  0.34077874  1.39374522 -2.12753833  1.24093623]\n",
            "LogLoss: 0.5982404457564496\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 6\n",
            "Theta: [ 0.74066178  0.55523212  0.33129554  1.43620319 -2.13122628  1.09677987]\n",
            "LogLoss: 0.5559973608795439\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 7\n",
            "Theta: [ 0.64620522  0.56346175  0.3270635   1.4626339  -2.13235696  0.96847795]\n",
            "LogLoss: 0.5241267502772415\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 8\n",
            "Theta: [ 0.56182609  0.57039239  0.32617245  1.47758362 -2.13194897  0.8540029 ]\n",
            "LogLoss: 0.4994832006404109\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 9\n",
            "Theta: [ 0.48640502  0.57587674  0.32734433  1.48428114 -2.13067099  0.75173179]\n",
            "LogLoss: 0.48012708442582835\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = reg_log.predict_proba(X)\n"
      ],
      "metadata": {
        "id": "CyHKqh9GI3SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred = reg_log.predict(probs)"
      ],
      "metadata": {
        "id": "h5JPTyvDHNoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcvJgcToJriE",
        "outputId": "01265e91-7f8c-4dd3-c030-963596b95315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 1), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def auc_score(y, ypred):\n",
        "  accuracy = roc_auc_score(y, ypred)\n",
        "  print(f'Precisão: {(accuracy *100).round(2)}%')\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "K0EBF7egS8c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score(y, ypred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPeogL4cTK-2",
        "outputId": "4eae3872-9416-426e-af66-53c2def541ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão: 80.24%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8024330755036286"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "CNi5RebPPubx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_best(X_train, y_train, steps, rates):\n",
        "  for rate in rates:\n",
        "    for step in steps:\n",
        "        reg_log = regLogistica(learning_rate=rate, num_steps=step, limiar=0.8)\n",
        "        reg_log.fit(X_train, y_train)\n",
        "\n",
        "        ypred = reg_log.predict(reg_log.predict_proba(X_train))\n",
        "        score = reg_log.logloss_step\n",
        "\n",
        "        print(f'Steps: {step}')\n",
        "        print(f'Learning Rate: {rate}')\n",
        "        print(f'LogLoss: {score}')\n",
        "        print()  "
      ],
      "metadata": {
        "id": "rlzYAsJ8MSGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [2, 8, 16, 20]\n",
        "rates = [0.0001, 0.0005, 0.001, 0.005]\n",
        "\n",
        "search_best(X_train, y_train, steps=steps, rates=rates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGw10TXVOwne",
        "outputId": "e1f935aa-232c-4e66-c05c-c334ad25f814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 2\n",
            "Learning Rate: 0.0001\n",
            "LogLoss: 2.075086670841956\n",
            "\n",
            "Steps: 8\n",
            "Learning Rate: 0.0001\n",
            "LogLoss: 0.46352867279704374\n",
            "\n",
            "Steps: 16\n",
            "Learning Rate: 0.0001\n",
            "LogLoss: 0.4087133914178898\n",
            "\n",
            "Steps: 20\n",
            "Learning Rate: 0.0001\n",
            "LogLoss: 0.40324484806727995\n",
            "\n",
            "Steps: 2\n",
            "Learning Rate: 0.0005\n",
            "LogLoss: 0.46608173628076827\n",
            "\n",
            "Steps: 8\n",
            "Learning Rate: 0.0005\n",
            "LogLoss: 0.4025219485870364\n",
            "\n",
            "Steps: 16\n",
            "Learning Rate: 0.0005\n",
            "LogLoss: 0.40251871192896804\n",
            "\n",
            "Steps: 20\n",
            "Learning Rate: 0.0005\n",
            "LogLoss: 0.402518617859431\n",
            "\n",
            "Steps: 2\n",
            "Learning Rate: 0.001\n",
            "LogLoss: 0.6361259037496491\n",
            "\n",
            "Steps: 8\n",
            "Learning Rate: 0.001\n",
            "LogLoss: 0.4025294542887039\n",
            "\n",
            "Steps: 16\n",
            "Learning Rate: 0.001\n",
            "LogLoss: 0.40251862101588926\n",
            "\n",
            "Steps: 20\n",
            "Learning Rate: 0.001\n",
            "LogLoss: 0.40251863035387037\n",
            "\n",
            "Steps: 2\n",
            "Learning Rate: 0.005\n",
            "LogLoss: nan\n",
            "\n",
            "Steps: 8\n",
            "Learning Rate: 0.005\n",
            "LogLoss: nan\n",
            "\n",
            "Steps: 16\n",
            "Learning Rate: 0.005\n",
            "LogLoss: nan\n",
            "\n",
            "Steps: 20\n",
            "Learning Rate: 0.005\n",
            "LogLoss: nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in multiply\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_log = regLogistica(learning_rate=0.0005, num_steps=20, limiar=0.9, info=True)\n",
        "reg_log.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmGdtMtLQba2",
        "outputId": "b4513dd7-70c0-4e89-e3c8-56443b12218b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0\n",
            "Theta: [ 0.10348466 -0.37595466 -1.13612361  2.17649411  0.28787232  0.44417244]\n",
            "LogLoss: 2.0982811623026487\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 1\n",
            "Theta: [-0.0198917  -0.12127501 -0.90496857  2.00423798  0.43715305  0.28461909]\n",
            "LogLoss: 0.475258960666341\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 2\n",
            "Theta: [-0.08285961 -0.01043048 -0.77283717  1.84306239  0.51816689  0.16010748]\n",
            "LogLoss: 0.42947712293708\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 3\n",
            "Theta: [-0.10276518  0.01148275 -0.71376956  1.7211102   0.5509479   0.07305722]\n",
            "LogLoss: 0.4123800530338971\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 4\n",
            "Theta: [-1.03604113e-01  1.17184769e-03 -6.89863872e-01  1.63712553e+00\n",
            "  5.61831110e-01  1.88002299e-02]\n",
            "LogLoss: 0.40641306547927214\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 5\n",
            "Theta: [-0.09917987 -0.01275008 -0.67874164  1.58157666  0.56576046 -0.01234522]\n",
            "LogLoss: 0.4040567645947967\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 6\n",
            "Theta: [-0.09432321 -0.02297845 -0.67249904  1.54603949  0.56766581 -0.02926815]\n",
            "LogLoss: 0.40310069161367346\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 7\n",
            "Theta: [-0.09030059 -0.02944385 -0.66869343  1.5239601   0.56879877 -0.0381117 ]\n",
            "LogLoss: 0.4027311906640514\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 8\n",
            "Theta: [-0.08729516 -0.03331835 -0.66633936  1.51052769  0.56951511 -0.04259925]\n",
            "LogLoss: 0.40259467228651535\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 9\n",
            "Theta: [-0.08517394 -0.03559001 -0.66488952  1.50246175  0.56997054 -0.04482284]\n",
            "LogLoss: 0.4025455808370552\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 10\n",
            "Theta: [-0.08373161 -0.03690947 -0.66400218  1.49765311  0.57025808 -0.04590111]\n",
            "LogLoss: 0.40252815534892844\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 11\n",
            "Theta: [-0.08277628 -0.0376732  -0.66346172  1.49479634  0.57043818 -0.0464123 ]\n",
            "LogLoss: 0.4025219960135626\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 12\n",
            "Theta: [-0.08215549 -0.0381151  -0.6631336   1.49310128  0.57055022 -0.04664814]\n",
            "LogLoss: 0.4025198177900739\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 13\n",
            "Theta: [-0.08175783 -0.03837112 -0.66293483  1.49209553  0.57061955 -0.04675299]\n",
            "LogLoss: 0.4025190454192985\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 14\n",
            "Theta: [-0.08150588 -0.03851976 -0.66281459  1.49149837  0.57066226 -0.04679704]\n",
            "LogLoss: 0.40251877062551406\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 15\n",
            "Theta: [-0.08134762 -0.03860629 -0.66274193  1.49114347  0.57068848 -0.0468138 ]\n",
            "LogLoss: 0.4025186725352258\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 16\n",
            "Theta: [-0.08124889 -0.0386568  -0.66269806  1.4909323   0.57070453 -0.0468189 ]\n",
            "LogLoss: 0.4025186374179078\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 17\n",
            "Theta: [-0.08118764 -0.03868636 -0.66267158  1.49080651  0.57071433 -0.04681943]\n",
            "LogLoss: 0.40251862481455924\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 18\n",
            "Theta: [-0.08114981 -0.03870371 -0.6626556   1.49073151  0.5707203  -0.04681845]\n",
            "LogLoss: 0.4025186202822915\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n",
            "Step: 19\n",
            "Theta: [-0.08112653 -0.03871391 -0.66264596  1.49068673  0.57072394 -0.0468172 ]\n",
            "LogLoss: 0.4025186186498817\n",
            "\n",
            "Model Trained!\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = reg_log.predict_proba(X_train)\n",
        "ypred = reg_log.predict(probs)"
      ],
      "metadata": {
        "id": "TabSWOESSdCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score(y_train, ypred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ExiDax7MQBi",
        "outputId": "11325322-7342-446b-ca13-f4fdb7a9bc21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão: 80.6%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8060482688119472"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validando o modelo\n",
        "\n",
        "reg_log = regLogistica(learning_rate=0.0005, num_steps=20, limiar=0.9, info=False)\n",
        "reg_log.fit(X_test, y_test)"
      ],
      "metadata": {
        "id": "YAW1D2tNT9Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_probs = reg_log.predict_proba(X_test)\n",
        "test_predict = reg_log.predict(test_probs)"
      ],
      "metadata": {
        "id": "-AJQ3g-oUziR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc_score(y_test, test_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_86J7i6ULJR",
        "outputId": "a6fd3edd-77c2-4d15-f0aa-c1c0c8fb882c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisão: 78.04%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7803793388424461"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTJyvAhVUxVW",
        "outputId": "83ba3527-5267-46bc-9510-664b71ed461d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.21802299,  0.47654171, -0.90943223,  0.26959324,  0.88071171],\n",
              "       [ 1.06258502,  0.30328486,  1.08917429,  0.28639959,  0.3806207 ],\n",
              "       [ 0.99291911,  0.31148497,  0.94097061,  0.28191356, -0.46596404],\n",
              "       ...,\n",
              "       [-1.26708786, -0.55511661, -0.76978544, -0.43996549,  0.66656636],\n",
              "       [ 0.73507723,  0.40140819,  0.22955105,  0.29562512, -1.32870576],\n",
              "       [-0.82854793,  0.3254663 , -2.38589945,  0.06263802, -0.29400079]])"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_log.predict(reg_log.predict_proba(np.array([[ 0.21802299,  0.47654171, -0.90943223,  0.26959324,  0.88071171]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jopL6LRrYuVK",
        "outputId": "7290606c-27d8-4121-b8cf-bf9e41c9ffb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0]])"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    }
  ]
}